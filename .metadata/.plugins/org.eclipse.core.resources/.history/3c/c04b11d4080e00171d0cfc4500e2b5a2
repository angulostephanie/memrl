package myProj;

import burlap.behavior.singleagent.Episode;
import burlap.behavior.singleagent.learning.LearningAgent;
import burlap.behavior.singleagent.learning.tdmethods.QLearning;
import burlap.domain.singleagent.gridworld.GridWorldDomain;
import burlap.domain.singleagent.gridworld.GridWorldVisualizer;
import burlap.domain.singleagent.gridworld.state.GridAgent;
import burlap.domain.singleagent.gridworld.state.GridLocation;
import burlap.domain.singleagent.gridworld.state.GridWorldState;
import burlap.mdp.singleagent.environment.SimulatedEnvironment;
import burlap.mdp.core.state.State;
import burlap.mdp.singleagent.SADomain;
import burlap.shell.visual.VisualExplorer;
import burlap.visualizer.Visualizer;

public class TMazeGrid {

	public static void main(String[] args) {
		GridWorldDomain tmaze = new GridWorldDomain(3,2); //3x2 grid world
		tmaze.verticalWall(1, 1, 0); //left wall
		tmaze.verticalWall(1, 1, 2); //right wall
		
		SADomain domain = tmaze.generateDomain(); //generate the grid world domain
		
		//setup initial state
		State s = new GridWorldState(new GridAgent(1, 1), new GridLocation(2, 0, "happy face"));
		
		
		
		//create visualizer and explorer
		Visualizer v = GridWorldVisualizer.getVisualizer(tmaze.getMap());
		VisualExplorer exp = new VisualExplorer(domain, v, s);

		//control keys = w-s-a-d, manually control agent
		exp.addKeyAction("w", GridWorldDomain.ACTION_NORTH, "up");
		exp.addKeyAction("s", GridWorldDomain.ACTION_SOUTH, "down");
		exp.addKeyAction("a", GridWorldDomain.ACTION_WEST, "left");
		exp.addKeyAction("d", GridWorldDomain.ACTION_EAST, "right");
		
		
		exp.initGUI();
		
		SimulatedEnvironment env = new SimulatedEnvironment(domain, s);
		for(int i = 0; i<100; i++) {
			System.out.println("Episode " + (i+1));
			env.resetEnvironment();
		}
		
	}

	public void QLearningExample(String outputPath){
		
		LearningAgent agent = new QLearning(domain, 0.99, hashingFactory, 0., 1.);

		//run learning for 50 episodes
		for(int i = 0; i < 50; i++){
			Episode e = agent.runLearningEpisode(env);

			e.write(outputPath + "ql_" + i);
			System.out.println(i + ": " + e.maxTimeStep());

			//reset environment for next learning episode
			env.resetEnvironment();
		}
		
	}

}
